{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90aaebd8",
   "metadata": {},
   "source": [
    "#### 네이버 뉴스 크롤링\n",
    "##### 2020-01~2020-10\n",
    "##### 기사날짜 이른 순으로 정렬, 기사날짜 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d324fd1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:21.808624Z",
     "start_time": "2021-09-06T04:54:21.085969Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bebfce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:22.506668Z",
     "start_time": "2021-09-06T04:54:22.502420Z"
    }
   },
   "outputs": [],
   "source": [
    "date = str(datetime.now())\n",
    "date = date[: date.rfind(':')].replace(' ', '_')\n",
    "date = date.replace(':', '시') + '분'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310ede19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:29.503624Z",
     "start_time": "2021-09-06T04:54:23.701815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 키워드를 입력하세요 : 홈트\n",
      "총 필요한 뉴스기사를 입력해주세요(숫자만 입력) : 10\n"
     ]
    }
   ],
   "source": [
    "#예시로 구현.. 전체 몇개인지 카운트 필요..?\n",
    "query = input('검색 키워드를 입력하세요 : ')\n",
    "query = query.replace('', '+')\n",
    "news_num = int(input('총 필요한 뉴스기사를 입력해주세요(숫자만 입력) : '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d865bd29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:31.805855Z",
     "start_time": "2021-09-06T04:54:31.418476Z"
    }
   },
   "outputs": [],
   "source": [
    "news_url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'\n",
    "req = requests.get(news_url.format(query))\n",
    "soup = BeautifulSoup(req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8ff124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:32.955487Z",
     "start_time": "2021-09-06T04:54:32.952005Z"
    }
   },
   "outputs": [],
   "source": [
    "news_dict = {}\n",
    "idx = 0 \n",
    "cur_page = 1 #뉴스 갯수가 더 많으면 다음 페이지로 넘어가야 하니까 기억해둘것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "779e8aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:33.871708Z",
     "start_time": "2021-09-06T04:54:33.597760Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "크롤링 !!!!!!! 성공했으면 좋겠어..무척...\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('크롤링 !!!!!!! 성공했으면 좋겠어..무척...')\n",
    "\n",
    "while idx < news_num:\n",
    "    \n",
    "    table = soup.find('ul',{'class' : 'list_news'})\n",
    "    li_list = table.find_all('li', {'id': re.compile('sp_nws.*')})\n",
    "    area_list = [li.find('div', {'class' : 'news_area'}) for li in li_list]\n",
    "    a_list = [area.find('a', {'class' : 'news_tit'}) for area in area_list]\n",
    "    \n",
    "    for n in a_list[:min(len(a_list), news_num-idx)]:\n",
    "        news_dict[idx] = {'title' : n.get('title'),\n",
    "                          'url' : n.get('href') }\n",
    "        idx += 1\n",
    "\n",
    "    cur_page += 1\n",
    "    \n",
    "    pages = soup.find('div', {'class' : 'sc_page_inner'})\n",
    "    next_page_url = [p for p in pages.find_all('a') if p.text == str(cur_page)][0].get('href')\n",
    "    \n",
    "    req = requests.get('https://search.naver.com/search.naver' + next_page_url)\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435c32f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:34.797694Z",
     "start_time": "2021-09-06T04:54:34.745184Z"
    }
   },
   "outputs": [],
   "source": [
    "#일단 엑셀로 뽑아보까.. csv로 ..?\n",
    "news_df = DataFrame(news_dict).T\n",
    "folder_path = os.getcwd()\n",
    "xlsx_file_name = '네이버뉴스_{}_{}.xlsx'.format(query, date)\n",
    "news_df.to_excel(xlsx_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a0822",
   "metadata": {},
   "source": [
    "###### 아니 이거 페이지 기간설정 어떻게..?\n",
    "###### 실제 입력해야되는데..? 아예 설정된 페이지를 가져와서 데이터 추출?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528c0be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:37.195909Z",
     "start_time": "2021-09-06T04:54:37.192260Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e8860f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:38.138154Z",
     "start_time": "2021-09-06T04:54:37.847726Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://search.naver.com/search.naver?where=news&query=%ED%99%88%ED%8A%B8&sm=tab_opt&sort=2&photo=0&field=0&pd=2&ds=&de=&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3A1m&is_sug_officeid=0'\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36',\n",
    "          'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d226f5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:54:38.867046Z",
     "start_time": "2021-09-06T04:54:38.844155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"주말의 홈트｜한수진의 요가 한 수, ‘누워서 하는 힙업 운동'\",\n",
       " \"용인시 비대면 신체활동 프로그램 '홈트조아용' 진행\",\n",
       " \"김종국·엄정화 '홈트' 영상 인기 폭발…무턱대고 따라했다간 [건강!톡]\",\n",
       " '코로나 속 폭염…집콕 여름휴가 위한 IT기기는',\n",
       " \"'슈돌' 찐건나블리, 헬스장 오픈…'세젤귀' 홈트 현장 공개\",\n",
       " \"'슈돌'\\xa0찐건나블리, 세젤귀 헬스장 오픈..열정 가득 홈트\",\n",
       " '‘슈돌’ 찐건나블리, 헛둘헛둘 홈트에 빠졌다',\n",
       " \"[사람이답이다] 나랑드사이다의 든든한 '뒷배' 노광수 브랜드 매니저\",\n",
       " '‘슈돌’ 찐건나블리, 헬스장 오픈...열정 가득 홈트 현장',\n",
       " '[우리들의 목소리] 여름방학 동안 해볼 만한 것들']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#기사제목\n",
    "soup.find_all('a', attrs={'class':'news_tit'})\n",
    "[title['title'] for title in soup.find_all('a', attrs={'class':'news_tit'}) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817a0d52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:09.694673Z",
     "start_time": "2021-09-06T04:55:09.676361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"info\">2021.08.07.</span>,\n",
       " <span class=\"info\">2021.08.07.</span>,\n",
       " <span class=\"info\">2021.08.07.</span>,\n",
       " <span class=\"info\">2021.08.07.</span>,\n",
       " <span class=\"info\">2021.08.08.</span>,\n",
       " <span class=\"info\">2021.08.08.</span>,\n",
       " <span class=\"info\">2021.08.08.</span>,\n",
       " <span class=\"info\">2021.08.08.</span>,\n",
       " <span class=\"info\">2021.08.08.</span>,\n",
       " <span class=\"info\">2021.08.08.</span>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#기사주소\n",
    "[ url['href'] for url in soup.find_all('a', attrs={'class':'news_tit'}) ]\n",
    "\n",
    "#기사작성일-태그중복, 이상한거 가져오는데...?-정규표현식 정리?\n",
    "soup.find_all('span', attrs={'class':'info'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2940eb3",
   "metadata": {},
   "source": [
    "##### 이상한 거 다 버리고 날짜만 가져와보자꾸나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c8384b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:13.242706Z",
     "start_time": "2021-09-06T04:55:13.229783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021.08.07.',\n",
       " '2021.08.07.',\n",
       " '2021.08.07.',\n",
       " '2021.08.07.',\n",
       " '2021.08.08.',\n",
       " '2021.08.08.',\n",
       " '2021.08.08.',\n",
       " '2021.08.08.',\n",
       " '2021.08.08.',\n",
       " '2021.08.08.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = [ date.get_text() for date in soup.find_all('span', attrs={'class':'info'})]\n",
    "\n",
    "import re\n",
    "\n",
    "date_list = []\n",
    "for date in dates:\n",
    "    if re.search(r'\\d+.\\d+.\\d+.', date) != None:\n",
    "        date_list.append(date)\n",
    "\n",
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e78fa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:23.689440Z",
     "start_time": "2021-09-06T04:55:15.391580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6701\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start = 1\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        url = 'https://search.naver.com/search.naver?where=news&query=%ED%99%88%ED%8A%B8&sm=tab_opt&sort=2&photo=0&field=0&pd=2&ds=&de=&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3A1m&is_sug_officeid=0'.format(start)\n",
    "        headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36',\n",
    "          'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        news_title = [title['title'] for title in soup.find_all('a', attrs={'class':'news_tit'})] # 기사 제목\n",
    "        news_url = [ url['href'] for url in soup.find_all('a', attrs={'class':'news_tit'}) ] # 기사 url\n",
    "        \n",
    "        dates = [ date.get_text() for date in soup.find_all('span', attrs={'class':'info'})] # 기사 작성일\n",
    "        news_date = []\n",
    "        for date in dates:\n",
    "            if re.search(r'\\d+.\\d+.\\d+.', date) != None: # 기사 작성일 정제\n",
    "                news_date.append(date)\n",
    "        \n",
    "        df = pd.DataFrame({'기사작성일':news_date,'기사제목':news_title,'기사주소':news_url})\n",
    "        result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "        start += 10\n",
    "    \n",
    "    except: # 오류발생시 몇 페이지까지 크롤링했는지 page를 확인하기 \n",
    "        print(start)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8ef279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:58:10.881809Z",
     "start_time": "2021-09-06T04:58:10.874871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c5ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
