{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b228e45a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T14:13:37.423263Z",
     "start_time": "2021-12-25T14:13:31.811549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-facenet\n",
      "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: mtcnn in /Users/dayoung/opt/anaconda3/lib/python3.8/site-packages (from keras-facenet) (0.1.1)\n",
      "Requirement already satisfied: keras>=2.0.0 in /Users/dayoung/opt/anaconda3/lib/python3.8/site-packages (from mtcnn->keras-facenet) (2.7.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /Users/dayoung/opt/anaconda3/lib/python3.8/site-packages (from mtcnn->keras-facenet) (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/dayoung/opt/anaconda3/lib/python3.8/site-packages (from opencv-python>=4.1.0->mtcnn->keras-facenet) (1.20.1)\n",
      "Building wheels for collected packages: keras-facenet\n",
      "  Building wheel for keras-facenet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10385 sha256=4dd5fb0a5f9047c8e887afd08a24763793ab263048c6fd8b4af6c334c4f41656\n",
      "  Stored in directory: /Users/dayoung/Library/Caches/pip/wheels/dc/5f/3a/fa496ade459f1dcb2bdef3ad74cbdff2c90c28d09d6db39859\n",
      "Successfully built keras-facenet\n",
      "Installing collected packages: keras-facenet\n",
      "Successfully installed keras-facenet-0.3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install keras-facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1529a8cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T14:18:35.135837Z",
     "start_time": "2021-12-25T14:18:35.124450Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def download_and_verify(url, filepath, sha256=None):\n",
    "    os.makedirs(os.path.split(filepath)[0], exist_ok=True)\n",
    "    log.info('Looking for ' + filepath)\n",
    "    if not os.path.isfile(filepath) or (sha256\n",
    "                                        and sha256sum(filepath) != sha256):\n",
    "        log.info('Downloading ' + filepath)\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    assert sha256 == sha256sum(filepath), 'Error occurred verifying sha256.'\n",
    "\n",
    "\n",
    "def sha256sum(filename):\n",
    "    h = hashlib.sha256()\n",
    "    b = bytearray(128 * 1024)\n",
    "    mv = memoryview(b)\n",
    "    with open(filename, 'rb', buffering=0) as f:\n",
    "        for n in iter(lambda: f.readinto(mv), 0):\n",
    "            h.update(mv[:n])\n",
    "    return h.hexdigest()\n",
    "\n",
    "def cropBox(image, detection, margin):\n",
    "    x1, y1, w, h = detection['box']\n",
    "    x1 -= margin\n",
    "    y1 -= margin\n",
    "    w += 2*margin\n",
    "    h += 2*margin\n",
    "    if x1 < 0:\n",
    "        w += x1\n",
    "        x1 = 0\n",
    "    if y1 < 0:\n",
    "        h += y1\n",
    "        y1 = 0\n",
    "    return image[y1:y1+h, x1:x1+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ce3b2d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T14:19:01.645110Z",
     "start_time": "2021-12-25T14:19:01.631382Z"
    }
   },
   "outputs": [],
   "source": [
    "# flake8: noqa\n",
    "MODEL_METADATA = {\n",
    "    '20180402-114759': {\n",
    "        'zip_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20180402-114759.zip',\n",
    "        'zip_local_name': '20180402-114759.zip',\n",
    "        'zip_sha256': '669f37d3954b72b53121ff0638ca5bb8b14309bfe4767fe6bd851eee75f1f0de',\n",
    "        'dir_name': '20180402-114759',\n",
    "        'reader_prefix': 'model-20180402-114759.ckpt-275',\n",
    "        'dimensions': 512,\n",
    "        'subtract_mean': True,\n",
    "        'keras_sha256': 'c99bfb20ca9959afb7bb83a1a6f4b7fc65bacf471c7f945c15a39881057a56be',\n",
    "        'keras_weights_sha256': '8b71e7045497e841c00ee568f031d1a4d30908fceadf6884aef2dec4d545202b',\n",
    "        'keras_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20180402-114759.h5',\n",
    "        'keras_weights_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20180402-114759-weights.h5',\n",
    "        'fixed_image_standardization': True,\n",
    "        'keras_model_filename': '20180402-114759.h5',\n",
    "        'keras_weights_filename': '20180402-114759-weights.h5',\n",
    "        'distance_metric': 'cosine',\n",
    "        'image_size': 160,\n",
    "        'files': {\n",
    "            'protobuf': {\n",
    "                'name': '20180402-114759.pb',\n",
    "                'sha256': 'bf2c12f31880aaa865fa5a9c168dcbd619f7a40b1633f6446d416fac2421ab99'\n",
    "            },\n",
    "            'checkpoint': {\n",
    "                'name': 'model-20180402-114759.ckpt-275.data-00000-of-00001',\n",
    "                'sha256': '5ccfbec36aa87074e96507d1b2957c739ddd1ce928cdc8f31b70fd3f7091f25a'\n",
    "            },\n",
    "            'index': {\n",
    "                'name': 'model-20180402-114759.ckpt-275.index',\n",
    "                'sha256': '2f84bad893bc250af5a19dca9cf4690c13d0eb394ab09eb39a9f3480fedf3dce'\n",
    "            },\n",
    "            'meta': {\n",
    "                'name': 'model-20180402-114759.meta',\n",
    "                'sha256': 'b711e501998754794959573f0fbaa45da89cad3457b31c6de48ad53c87fce00c'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    '20180408-102900': {\n",
    "        'zip_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20180408-102900.zip',\n",
    "        'zip_local_name': '20180408-102900.zip',\n",
    "        'zip_sha256': '2a32a4d6b797b0e35e065c674dfa2d60e9eb2372aa10728bd0b221abe12490ac',\n",
    "        'dir_name': '20180408-102900',\n",
    "        'dimensions': 512,\n",
    "        'image_size': 160,\n",
    "        'keras_weights_sha256': 'af526097bd89ff84dda94dc071ff39c4cf39922cf0a9d9dea652853cda9616be',\n",
    "        'keras_sha256': '23cdb7f96553c3baa32fbb4f96aaa398a721ea26cd49de5a72c9beea6150d13e',\n",
    "        'keras_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20180408-102900.h5',\n",
    "        'keras_weights_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20180408-102900-weights.h5',\n",
    "        'reader_prefix': 'model-20180408-102900.ckpt-90',\n",
    "        'keras_model_filename': '20180408-102900.h5',\n",
    "        'keras_weights_filename': '20180408-102900-weights.h5',\n",
    "        'fixed_image_standardization': True,\n",
    "        'distance_metric': 'cosine',\n",
    "        'subtract_mean': True,\n",
    "        'files': {\n",
    "            'protobuf': {\n",
    "                'name': '20180408-102900.pb',\n",
    "                'sha256': '272568219fa6505371ceed76dca6b3925ef69b54962709cf76f763e9d8bf4cfb'\n",
    "            },\n",
    "            'checkpoint': {\n",
    "                'name': 'model-20180408-102900.ckpt-90.data-00000-of-00001',\n",
    "                'sha256': '15d3109b99a6ca0d49843c183d4b417f7952f2948a1c246e2059813157b9d385'\n",
    "            },\n",
    "            'index': {\n",
    "                'name': 'model-20180408-102900.ckpt-90.index',\n",
    "                'sha256': '548d743099cf13f598db8a660e9a8ad7f12148cb4206ab9cc480f0550edc17e9'\n",
    "            },\n",
    "            'meta': {\n",
    "                'name': 'model-20180408-102900.meta',\n",
    "                'sha256': '238c98fc44fd0db79f61e719646b55c22b6a79944f806f8ee23e2d9f36c9ae7d'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    '20170511-185253': {\n",
    "        'zip_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20170511-185253.zip',\n",
    "        'zip_sha256': '0dd66caa1e9b7a7c91424bca150a66da193c4e626e75bfa50ff406180a09c7e9',\n",
    "        'keras_model_filename': '20170511-185253.h5',\n",
    "        'keras_weights_filename': '20170511-185253-weights.h5',\n",
    "        'keras_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20170511-185253.h5',\n",
    "        'keras_weights_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20170511-185253-weights.h5',\n",
    "        'keras_sha256': 'd7dbcee552427cd497190894ad5c9763313c3249f0b5dc2d6e0cc3e42d5ea063',\n",
    "        'keras_weights_sha256': '28db99aaafce0e62b2cdb1db5ac733ffa9e52a365e1a3ca0a13c5159bd4363c4',\n",
    "        'zip_local_name': '20170511-185253.zip',\n",
    "        'reader_prefix': 'model-20170511-185253.ckpt-80000',\n",
    "        'dir_name': '20170511-185253',\n",
    "        'dimensions': 128,\n",
    "        'image_size': 160,\n",
    "        'fixed_image_standardization': False,\n",
    "        'distance_metric': 'euclidean',\n",
    "        'subtract_mean': False,\n",
    "        'files': {\n",
    "            'protobuf': {\n",
    "                'name': '20170511-185253.pb',\n",
    "                'sha256': '71fb49617aee7b007b66ed1e4474e749212ed9872ff3b47c25ee997c8262baa4'\n",
    "            },\n",
    "            'checkpoint': {\n",
    "                'name': 'model-20170511-185253.ckpt-80000.data-00000-of-00001',\n",
    "                'sha256': '8776a47ef7fd0a5848946295a763c2c10580c621f84f591d731f8c2b6d8eabf5'\n",
    "            },\n",
    "            'index': {\n",
    "                'name': 'model-20170511-185253.ckpt-80000.index',\n",
    "                'sha256': 'e6fabc0cfe23470b878064d5692f6771c90d0cd4e1562d6785742feb5465c1cd'\n",
    "            },\n",
    "            'meta': {\n",
    "                'name': 'model-20170511-185253.meta',\n",
    "                'sha256': '3b4c63501786e9a0a9354b6044d0dc8205b788c173de9a503df7e5793b4d3953'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    '20170512-110547': {\n",
    "        'zip_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20170512-110547.zip',\n",
    "        'zip_sha256': '24a020c3d7794a590d834c4963f8a7c59819b8950a54fcb08e10b2a253ab0a30',\n",
    "        'keras_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20170512-110547.h5',\n",
    "        'keras_weights_url': 'https://github.com/faustomorales/keras-facenet/releases/download/v0.3.1/20170512-110547-weights.h5',\n",
    "        'keras_sha256': '0ce0e39b5c8b5a46b7005c520441e9776f058d650a66d7ef0ec28b67a8d06d6c',\n",
    "        'keras_weights_sha256': '668e950140ad76f1e21e3a2bc1d3ad9c673734ea8ea1abbf4ecc44d1dbdd400b',\n",
    "        'keras_model_filename': '20170512-110547.h5',\n",
    "        'keras_weights_filename': '20170512-110547-weights.h5',\n",
    "        'zip_local_name': '20170512-110547.zip',\n",
    "        'dir_name': '20170512-110547',\n",
    "        'dimensions': 128,\n",
    "        'image_size': 160,\n",
    "        'fixed_image_standardization': False,\n",
    "        'distance_metric': 'euclidean',\n",
    "        'subtract_mean': False,\n",
    "        'reader_prefix': 'model-20170512-110547.ckpt-250000',\n",
    "        'files': {\n",
    "            'protobuf': {\n",
    "                'name': '20170512-110547.pb',\n",
    "                'sha256': '8bdc3aed34e577113a656b8e5d0274346f8967fa7f0f9d6f3fdcd9608a29b9e4'\n",
    "            },\n",
    "            'checkpoint': {\n",
    "                'name': 'model-20170512-110547.ckpt-250000.data-00000-of-00001',\n",
    "                'sha256': '08bb31fc541d7cd2fcd2c499a1d90de45140828f0d08d23c34b65fab2d172ebb'\n",
    "            },\n",
    "            'index': {\n",
    "                'name': 'model-20170512-110547.ckpt-250000.index',\n",
    "                'sha256': '3dead9312945700df490239a1795fe0cd5f667984242a9203aa035d899c3e198'\n",
    "            },\n",
    "            'meta': {\n",
    "                'name': 'model-20170512-110547.meta',\n",
    "                'sha256': '1f3bb46a87c0bcb822ae1624e7c018d81de36889acb0e5641b5580476553a8dc'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4048d2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T14:19:33.121599Z",
     "start_time": "2021-12-25T14:19:33.085890Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Inception-ResNet V1 model for tensorflow.keras.\n",
    "# Reference\n",
    "http://arxiv.org/abs/1602.07261\n",
    "https://github.com/davidsandberg/facenet/blob/master/src/models/inception_resnet_v1.py\n",
    "https://github.com/myutwo150/keras-inception-resnet-v2/blob/master/inception_resnet_v2.py\n",
    "\"\"\"\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def scaling(x, scale):\n",
    "    return x * scale\n",
    "\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "    x = Conv2D(filters,\n",
    "               kernel_size,\n",
    "               strides=strides,\n",
    "               padding=padding,\n",
    "               use_bias=use_bias,\n",
    "               name=name)(x)\n",
    "    if not use_bias:\n",
    "        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "        bn_name = _generate_layer_name('BatchNorm', prefix=name)\n",
    "        x = BatchNormalization(axis=bn_axis,\n",
    "                               momentum=0.995,\n",
    "                               epsilon=0.001,\n",
    "                               scale=False,\n",
    "                               name=bn_name)(x)\n",
    "    if activation is not None:\n",
    "        ac_name = _generate_layer_name('Activation', prefix=name)\n",
    "        x = Activation(activation, name=ac_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _generate_layer_name(name, branch_idx=None, prefix=None):\n",
    "    if prefix is None:\n",
    "        return None\n",
    "    if branch_idx is None:\n",
    "        return '_'.join((prefix, name))\n",
    "    return '_'.join((prefix, 'Branch', str(branch_idx), name))\n",
    "\n",
    "\n",
    "def _inception_resnet_block(x, scale, block_type, block_idx,\n",
    "                            activation='relu'):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    if block_idx is None:\n",
    "        prefix = None\n",
    "    else:\n",
    "        prefix = '_'.join((block_type, str(block_idx)))\n",
    "    name_fmt = partial(_generate_layer_name, prefix=prefix)\n",
    "\n",
    "    if block_type == 'Block35':\n",
    "        branch_0 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1,\n",
    "                             32,\n",
    "                             3,\n",
    "                             name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "        branch_2 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "        branch_2 = conv2d_bn(branch_2,\n",
    "                             32,\n",
    "                             3,\n",
    "                             name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "        branch_2 = conv2d_bn(branch_2,\n",
    "                             32,\n",
    "                             3,\n",
    "                             name=name_fmt('Conv2d_0c_3x3', 2))\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'Block17':\n",
    "        branch_0 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1,\n",
    "                             128, [1, 7],\n",
    "                             name=name_fmt('Conv2d_0b_1x7', 1))\n",
    "        branch_1 = conv2d_bn(branch_1,\n",
    "                             128, [7, 1],\n",
    "                             name=name_fmt('Conv2d_0c_7x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'Block8':\n",
    "        branch_0 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1,\n",
    "                             192, [1, 3],\n",
    "                             name=name_fmt('Conv2d_0b_1x3', 1))\n",
    "        branch_1 = conv2d_bn(branch_1,\n",
    "                             192, [3, 1],\n",
    "                             name=name_fmt('Conv2d_0c_3x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"Block35\", \"Block17\" or \"Block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "\n",
    "    mixed = Concatenate(axis=channel_axis,\n",
    "                        name=name_fmt('Concatenate'))(branches)\n",
    "    up = conv2d_bn(mixed,\n",
    "                   K.int_shape(x)[channel_axis],\n",
    "                   1,\n",
    "                   activation=None,\n",
    "                   use_bias=True,\n",
    "                   name=name_fmt('Conv2d_1x1'))\n",
    "    up = Lambda(scaling,\n",
    "                output_shape=K.int_shape(up)[1:],\n",
    "                arguments={'scale': scale})(up)\n",
    "    x = add([x, up])\n",
    "    if activation is not None:\n",
    "        x = Activation(activation, name=name_fmt('Activation'))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionResNetV1(input_shape=(160, 160, 3),\n",
    "                      classes=128,\n",
    "                      dropout_keep_prob=0.8,\n",
    "                      weights_path=None):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = conv2d_bn(inputs,\n",
    "                  32,\n",
    "                  3,\n",
    "                  strides=2,\n",
    "                  padding='valid',\n",
    "                  name='Conv2d_1a_3x3')\n",
    "    x = conv2d_bn(x, 32, 3, padding='valid', name='Conv2d_2a_3x3')\n",
    "    x = conv2d_bn(x, 64, 3, name='Conv2d_2b_3x3')\n",
    "    x = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n",
    "    x = conv2d_bn(x, 80, 1, padding='valid', name='Conv2d_3b_1x1')\n",
    "    x = conv2d_bn(x, 192, 3, padding='valid', name='Conv2d_4a_3x3')\n",
    "    x = conv2d_bn(x, 256, 3, strides=2, padding='valid', name='Conv2d_4b_3x3')\n",
    "\n",
    "    # 5x Block35 (Inception-ResNet-A block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.17,\n",
    "                                    block_type='Block35',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 6a (Reduction-A block):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_6a')\n",
    "    branch_0 = conv2d_bn(x,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1, 192, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 2))(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_6a')(branches)\n",
    "\n",
    "    # 10x Block17 (Inception-ResNet-B block):\n",
    "    for block_idx in range(1, 11):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.1,\n",
    "                                    block_type='Block17',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_7a')\n",
    "    branch_0 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 0))\n",
    "    branch_0 = conv2d_bn(branch_0,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_2 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "    branch_2 = conv2d_bn(branch_2,\n",
    "                         256,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 2))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 3))(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_7a')(branches)\n",
    "\n",
    "    # 5x Block8 (Inception-ResNet-C block):\n",
    "    for block_idx in range(1, 6):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.2,\n",
    "                                    block_type='Block8',\n",
    "                                    block_idx=block_idx)\n",
    "    x = _inception_resnet_block(x,\n",
    "                                scale=1.,\n",
    "                                activation=None,\n",
    "                                block_type='Block8',\n",
    "                                block_idx=6)\n",
    "\n",
    "    # Classification block\n",
    "    x = GlobalAveragePooling2D(name='AvgPool')(x)\n",
    "    x = Dropout(1.0 - dropout_keep_prob, name='Dropout')(x)\n",
    "    # Bottleneck\n",
    "    x = Dense(classes, use_bias=False, name='Bottleneck')(x)\n",
    "    bn_name = _generate_layer_name('BatchNorm', prefix='Bottleneck')\n",
    "    x = BatchNormalization(momentum=0.995,\n",
    "                           epsilon=0.001,\n",
    "                           scale=False,\n",
    "                           name=bn_name)(x)\n",
    "    x = Lambda(K.l2_normalize, arguments={'axis': 1}, name='normalize')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs, x, name='inception_resnet_v1')\n",
    "    if weights_path is not None:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff69b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T14:25:56.097771Z",
     "start_time": "2021-12-25T14:25:56.064958Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inception_resnet_v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-73d76c381fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minception_resnet_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInceptionResNetV1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msha256sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_and_verify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inception_resnet_v1'"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from inception_resnet_v1 import InceptionResNetV1\n",
    "from utils import sha256sum, download_and_verify\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# regex for renaming the tensors to their corresponding Keras counterpart\n",
    "RE_REPEAT = re.compile(r'Repeat_[0-9_]*b')\n",
    "RE_BLOCK8 = re.compile(r'Block8_[A-Za-z]')\n",
    "\n",
    "\n",
    "def get_filename(key):\n",
    "    filename = str(key)\n",
    "    filename = filename.replace('/', '_')\n",
    "    filename = filename.replace('InceptionResnetV1_', '')\n",
    "\n",
    "    # remove \"Repeat\" scope from filename\n",
    "    filename = RE_REPEAT.sub('B', filename)\n",
    "\n",
    "    if RE_BLOCK8.match(filename):\n",
    "        # the last block8 has different name with the previous 5 occurrences\n",
    "        filename = filename.replace('Block8', 'Block8_6')\n",
    "\n",
    "    # from TF to Keras naming\n",
    "    filename = filename.replace('_weights', '_kernel')\n",
    "    filename = filename.replace('_biases', '_bias')\n",
    "\n",
    "    return filename + '.npy'\n",
    "\n",
    "\n",
    "def verify_files(metadata, cache_folder):\n",
    "    for k, v in metadata['files'].items():\n",
    "        filepath = os.path.join(cache_folder, metadata['dir_name'], v['name'])\n",
    "        if not os.path.isfile(filepath) or sha256sum(filepath) != v['sha256']:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def download_tf_model(metadata, cache_folder):\n",
    "    \"\"\"Get TensorFlow model files.\n",
    "    \"\"\"\n",
    "    os.makedirs(cache_folder, exist_ok=True)\n",
    "    zip_url = metadata['zip_url']\n",
    "    zip_path = os.path.join(cache_folder, metadata['zip_local_name'])\n",
    "    dir_path = os.path.join(cache_folder, metadata['dir_name'])\n",
    "    download_and_verify(\n",
    "        url=zip_url, filepath=zip_path, sha256=metadata.get('zip_sha256')\n",
    "    )\n",
    "    if not os.path.isdir(dir_path) or not verify_files(metadata, cache_folder):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            log.info('Extracting files.')\n",
    "            zip_ref.extractall(cache_folder)\n",
    "    assert verify_files(metadata, cache_folder), 'Error occurred verifying file hashes.'  # noqa: E501\n",
    "\n",
    "\n",
    "def get_keras_model_from_tensorflow(metadata, cache_folder):\n",
    "    if not verify_files(metadata, cache_folder):\n",
    "        download_tf_model(metadata, cache_folder)\n",
    "    model_dir = os.path.join(cache_folder, metadata['dir_name'])\n",
    "    npy_weights_dir = os.path.join(model_dir, 'npy')\n",
    "    model_dir = model_dir\n",
    "\n",
    "    os.makedirs(npy_weights_dir, exist_ok=True)\n",
    "\n",
    "    weights_filename = metadata['keras_weights_filename']\n",
    "    model_filename = metadata['keras_model_filename']\n",
    "\n",
    "    log.info('Loading TensorFlow weights.')\n",
    "    reader = tf.train.NewCheckpointReader(\n",
    "        os.path.join(model_dir, metadata['reader_prefix'])\n",
    "    )\n",
    "    for key in reader.get_variable_to_shape_map():\n",
    "        # not saving the following tensors\n",
    "        if key == 'global_step':\n",
    "            continue\n",
    "        if 'AuxLogit' in key:\n",
    "            continue\n",
    "\n",
    "        # convert tensor name into the corresponding Keras layer weight name\n",
    "        # and save\n",
    "        path = os.path.join(npy_weights_dir, get_filename(key))\n",
    "        arr = reader.get_tensor(key)\n",
    "        np.save(path, arr)\n",
    "\n",
    "    log.info('Building Inception model.')\n",
    "    model = InceptionResNetV1(\n",
    "        input_shape=(None, None, 3),\n",
    "        classes=metadata['dimensions']\n",
    "    )\n",
    "\n",
    "    log.info('Loading numpy weights from ' + npy_weights_dir)\n",
    "    for layer in model.layers:\n",
    "        if layer.weights:\n",
    "            weights = []\n",
    "            for w in layer.weights:\n",
    "                log.info('Loading weights for ' + layer.name)\n",
    "                weight_name = os.path.basename(w.name).replace(':0', '')\n",
    "                weight_file = layer.name + '_' + weight_name + '.npy'\n",
    "                weight_arr = np.load(os.path.join(npy_weights_dir, weight_file))  # noqa: E501\n",
    "                weights.append(weight_arr)\n",
    "            layer.set_weights(weights)\n",
    "\n",
    "    log.info('Saving weights...')\n",
    "    model.save_weights(os.path.join(model_dir, weights_filename))\n",
    "    log.info('Saving model...')\n",
    "    model.save(os.path.join(model_dir, model_filename))\n",
    "    log.info('Cleaning up numpy weights...')\n",
    "    shutil.rmtree(npy_weights_dir)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_keras_model_from_prebuilt(metadata, cache_folder):\n",
    "    log.info('Loading weights.')\n",
    "    weights_filepath = os.path.join(\n",
    "        cache_folder,\n",
    "        metadata['dir_name'],\n",
    "        metadata['keras_weights_filename']\n",
    "    )\n",
    "    download_and_verify(\n",
    "        url=metadata['keras_weights_url'],\n",
    "        filepath=weights_filepath,\n",
    "        sha256=metadata['keras_weights_sha256']\n",
    "    )\n",
    "    model = InceptionResNetV1(\n",
    "        input_shape=(None, None, 3),\n",
    "        classes=metadata['dimensions']\n",
    "    )\n",
    "    model.load_weights(weights_filepath)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2181c267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T14:14:58.835548Z",
     "start_time": "2021-12-25T14:14:58.800368Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'embedding_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fe9452f7fa42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'embedding_model'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from scipy import spatial\n",
    "import cv2\n",
    "\n",
    "import embedding_model, metadata, utils\n",
    "import numpy as np\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class FaceNet:\n",
    "    \"\"\"An object wrapping the FaceNet embedding model.\n",
    "\n",
    "    Args:\n",
    "        key: Which version of the model to use. Options\n",
    "            are: 20180402-114759, 20180408-102900, 20170511-185253,\n",
    "            and 20170512-110547\n",
    "        use_prebuilt: Whether to use a prebuilt Keras model. If False,\n",
    "            a Keras model is build from the TensorFlow protobuf files\n",
    "            provided by David Sandberg (see\n",
    "            https://github.com/davidsandberg/facenet for details)\n",
    "        cache_folder: Where to save and look for model weights (defaults\n",
    "            to ~/.keras-facenet)\n",
    "\n",
    "    Attributes:\n",
    "        metadata: The metadata for the selected model\n",
    "        cache_folder: The cache folder for the wrapper\n",
    "        emb\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        key='20180402-114759',\n",
    "        use_prebuilt=True,\n",
    "        cache_folder='~/.keras-facenet'\n",
    "    ):\n",
    "        if key not in metadata.MODEL_METADATA:\n",
    "            raise NotImplementedError('Did not recognize key: ' + key)\n",
    "        self.metadata = metadata.MODEL_METADATA[key]\n",
    "        self.cache_folder = os.path.expanduser(cache_folder)\n",
    "        if use_prebuilt:\n",
    "            builder = embedding_model.get_keras_model_from_prebuilt\n",
    "        else:\n",
    "            builder = embedding_model.get_keras_model_from_tensorflow\n",
    "        self.model = builder(self.metadata, self.cache_folder)\n",
    "\n",
    "    def _normalize(self, image):\n",
    "        if self.metadata['fixed_image_standardization']:\n",
    "            return (np.float32(image) - 127.5) / 127.5\n",
    "        else:\n",
    "            mean = np.mean(image)\n",
    "            std = np.std(image)\n",
    "            std_adj = np.maximum(std, 1.0/np.sqrt(image.size))\n",
    "            y = np.multiply(np.subtract(image, mean), 1/std_adj)\n",
    "            return y\n",
    "\n",
    "    @classmethod\n",
    "    def mtcnn(cls):\n",
    "        if not hasattr(cls, '_mtcnn'):\n",
    "            from mtcnn.mtcnn import MTCNN\n",
    "            cls._mtcnn = MTCNN()\n",
    "        return cls._mtcnn\n",
    "    \n",
    "    def crop(self, filepath_or_image, threshold=0.95):\n",
    "        \"\"\"Get face crops from images.\n",
    "\n",
    "        Args:\n",
    "            filepath_or_image: The input image (see extract)\n",
    "            threshold: The threshold to use for face detection\n",
    "        \"\"\"\n",
    "        if isinstance(filepath_or_image, str):\n",
    "            image = cv2.imread(filepath_or_image)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            image = filepath_or_image\n",
    "        detections = [detection for detection in self.mtcnn().detect_faces(image) if detection['confidence'] > threshold]\n",
    "        if not detections:\n",
    "            return [], []\n",
    "        margin = int(0.1*self.metadata['image_size'])\n",
    "        crops = [utils.cropBox(image, detection=d, margin=margin) for d in detections]\n",
    "        return detections, crops\n",
    "\n",
    "    def extract(self, filepath_or_image, threshold=0.95):\n",
    "        \"\"\"Extract faces and compute embeddings in one go. Requires\n",
    "        mtcnn to be installed.\n",
    "\n",
    "        Args:\n",
    "            filepath_or_image: Path to image (or an image as RGB array)\n",
    "            threshold: The threshold for a face to be considered\n",
    "        Returns:\n",
    "            Same output as `mtcnn.MTCNN.detect_faces()` but enriched\n",
    "            with an \"embedding\" vector.\n",
    "        \"\"\"\n",
    "        detections, crops = self.crop(filepath_or_image, threshold=threshold)\n",
    "        if not detections:\n",
    "            return []\n",
    "        return [{**d, 'embedding': e} for d, e in zip(detections, self.embeddings(images=crops))]\n",
    "\n",
    "    def embeddings(self, images):\n",
    "        \"\"\"Compute embeddings for a set of images.\n",
    "\n",
    "        Args:\n",
    "            images: A list of images (cropped faces)\n",
    "\n",
    "        Returns:\n",
    "            Embeddings of shape (N, K) where N is the\n",
    "            number of cropepd faces and K is the dimensionality\n",
    "            of the selected model.\n",
    "        \"\"\"\n",
    "        s = self.metadata['image_size']\n",
    "        images = [cv2.resize(image, (s, s)) for image in images]\n",
    "        X = np.float32([self._normalize(image) for image in images])\n",
    "        embeddings = self.model.predict(X)\n",
    "        return embeddings\n",
    "\n",
    "    def compute_distance(self, embedding1, embedding2):\n",
    "        \"\"\"Compute the distance between two embeddings.\n",
    "\n",
    "        Args:\n",
    "            embedding1: The first embedding\n",
    "            embedding2: The second embedding\n",
    "\n",
    "        Returns:\n",
    "            The distance between the two embeddings.\n",
    "        \"\"\"\n",
    "        if self.metadata['distance_metric'] == 'cosine':\n",
    "            return spatial.distance.cosine(embedding1, embedding2)\n",
    "        elif self.metadata['distance_metric'] == 'euclidean':\n",
    "            return spatial.distance.euclidean(embedding1, embedding2)\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce13cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
